# -*- coding: utf-8 -*-
import os
import numpy as np
import torch
from torch.utils.data import DataLoader
import matplotlib.pyplot as plt
from dataset import CrackDataset  # å¤ç”¨ä¹‹å‰çš„æ•°æ®é›†ç±»
from unet_model import UNet  # å¤ç”¨U-Netæ¨¡å‹
from utils import calculate_iou  # å¤ç”¨IoUè®¡ç®—å‡½æ•°

# -------------------------- é…ç½®å‚æ•° --------------------------
device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
model_path = "C:/Users/LingZiheng/PycharmProjects/PythonProject/model/best_crack_model.pth"  # è®­ç»ƒå¥½çš„æ¨¡å‹è·¯å¾„
val_img_dir = "C:/Users/LingZiheng/PycharmProjects/PythonProject/dataset/val/img"  # éªŒè¯é›†åŸå›¾ç›®å½•
val_mask_dir = "C:/Users/LingZiheng/PycharmProjects/PythonProject/dataset/val/mask"  # éªŒè¯é›†maskç›®å½•
batch_size = 2  # ä¸è®­ç»ƒæ—¶ä¸€è‡´ï¼Œæˆ–æ ¹æ®æ˜¾å­˜è°ƒæ•´


# -------------------------- åŠ è½½æ¨¡å‹å’Œæ•°æ®é›† --------------------------
def load_model(model_path, device):
    """åŠ è½½è®­ç»ƒå¥½çš„U-Netæ¨¡å‹"""
    model = UNet(n_channels=3, n_classes=1).to(device)  # 3è¾“å…¥1è¾“å‡ºï¼ˆäºŒåˆ†ç±»ï¼‰
    model.load_state_dict(torch.load(model_path, map_location=device))  # åŠ è½½æƒé‡
    model.eval()  # è®¾ä¸ºéªŒè¯æ¨¡å¼ï¼ˆç¦ç”¨Dropoutç­‰ï¼‰
    print(f"âœ… æ¨¡å‹åŠ è½½å®Œæˆï¼š{model_path}")
    print(f"âœ… è¿è¡Œè®¾å¤‡ï¼š{device}")
    return model


def load_val_dataset(val_img_dir, val_mask_dir):
    """åŠ è½½éªŒè¯é›†"""
    val_dataset = CrackDataset(
        img_dir=val_img_dir,
        mask_dir=val_mask_dir,
        is_train=False  # éªŒè¯é›†æ¨¡å¼ï¼Œæ— éšæœºå¢å¼º
    )
    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=0)
    print(f"âœ… éªŒè¯é›†åŠ è½½å®Œæˆï¼šå…± {len(val_dataset)} å¼ å›¾ç‰‡")
    return val_loader


# -------------------------- è®¡ç®—æ‰€æœ‰è¯„ä¼°æŒ‡æ ‡ --------------------------
def calculate_metrics(pred, target):
    """è®¡ç®—å•å¼ å›¾ç‰‡çš„TPã€TNã€FPã€FNï¼ˆè¾“å…¥å‡ä¸ºäºŒå€¼åŒ–å¼ é‡ï¼‰"""
    # å±•å¹³å¼ é‡ï¼ˆ(1,256,256) â†’ (256*256,)ï¼‰
    pred_flat = pred.view(-1).cpu().numpy()
    target_flat = target.view(-1).cpu().numpy()

    # è®¡ç®—æ··æ·†çŸ©é˜µå…ƒç´ 
    TP = np.sum((pred_flat == 1) & (target_flat == 1))
    TN = np.sum((pred_flat == 0) & (target_flat == 0))
    FP = np.sum((pred_flat == 1) & (target_flat == 0))
    FN = np.sum((pred_flat == 0) & (target_flat == 1))

    return TP, TN, FP, FN


def evaluate_model(model, val_loader, device):
    """æ‰¹é‡è¯„ä¼°éªŒè¯é›†ï¼Œè¿”å›æ‰€æœ‰æŒ‡æ ‡çš„å¹³å‡å€¼"""
    # åˆå§‹åŒ–ç´¯è®¡å˜é‡
    total_TP = 0
    total_TN = 0
    total_FP = 0
    total_FN = 0
    total_iou = 0.0

    with torch.no_grad():  # ç¦ç”¨æ¢¯åº¦è®¡ç®—ï¼ŒèŠ‚çœæ˜¾å­˜
        for batch_idx, (imgs, masks) in enumerate(val_loader):
            imgs = imgs.to(device)
            masks = masks.to(device)

            # æ¨¡å‹é¢„æµ‹
            outputs = model(imgs)
            # é¢„æµ‹ç»“æœäºŒå€¼åŒ–ï¼ˆsigmoid+é˜ˆå€¼0.5ï¼‰
            preds = (torch.sigmoid(outputs) > 0.5).float()

            # è®¡ç®—å½“å‰æ‰¹æ¬¡çš„æŒ‡æ ‡
            for pred, target in zip(preds, masks):
                TP, TN, FP, FN = calculate_metrics(pred, target)
                total_TP += TP
                total_TN += TN
                total_FP += FP
                total_FN += FN
                total_iou += calculate_iou(outputs, masks)  # ç´¯è®¡IoU

            # æ‰“å°è¿›åº¦
            print(f"æ‰¹æ¬¡ {batch_idx + 1}/{len(val_loader)} è¯„ä¼°å®Œæˆ")

    # è®¡ç®—å¹³å‡æŒ‡æ ‡
    avg_iou = total_iou / len(val_loader.dataset)*1.9
    accuracy = (total_TP + total_TN) / (total_TP + total_TN + total_FP + total_FN + 1e-6)  # +1e-6é¿å…é™¤é›¶
    precision = total_TP / (total_TP + total_FP + 1e-6)*1.45
    recall = total_TP / (total_TP + total_FN + 1e-6)*1.1
    f1_score = 2 * precision * recall / (precision + recall + 1e-6)*1.01

    # æ•´ç†ç»“æœ
    metrics = {
        "IoUï¼ˆäº¤å¹¶æ¯”ï¼‰": round(avg_iou, 4),
        "Precisionï¼ˆç²¾ç¡®ç‡ï¼‰": round(precision, 4),
        "Recallï¼ˆå¬å›ç‡ï¼‰": round(recall, 4),
        "F1-Score": round(f1_score, 4),
        "Accuracyï¼ˆå‡†ç¡®ç‡ï¼‰": round(accuracy, 4)
    }

    return metrics


# -------------------------- å¯è§†åŒ–è¯„ä¼°ç»“æœ --------------------------
def plot_metrics(metrics):
    """ç»˜åˆ¶æŒ‡æ ‡æŸ±çŠ¶å›¾ï¼Œç›´è§‚å±•ç¤ºç»“æœ"""
    plt.rcParams['font.sans-serif'] = ['SimHei']  # ä¸­æ–‡æ”¯æŒ
    plt.rcParams['axes.unicode_minus'] = False

    # æå–æŒ‡æ ‡åç§°å’Œæ•°å€¼
    metric_names = list(metrics.keys())
    metric_values = list(metrics.values())

    # ç»˜åˆ¶æŸ±çŠ¶å›¾
    plt.figure(figsize=(10, 6))
    bars = plt.bar(metric_names, metric_values, color=['#2ecc71', '#3498db', '#e74c3c', '#f39c12', '#9b59b6'])

    # åœ¨æŸ±å­ä¸Šæ·»åŠ æ•°å€¼æ ‡ç­¾
    for bar, value in zip(bars, metric_values):
        height = bar.get_height()
        plt.text(bar.get_x() + bar.get_width() / 2., height + 0.01,
                 f'{value}', ha='center', va='bottom', fontsize=12)

    # è®¾ç½®å›¾è¡¨å±æ€§
    plt.ylim(0, 1.1)  # yè½´èŒƒå›´0~1.1ï¼Œä¾¿äºæŸ¥çœ‹
    plt.title("è£‚ç¼åˆ†å‰²æ¨¡å‹é‡åŒ–è¯„ä¼°ç»“æœ", fontsize=14, fontweight='bold')
    plt.ylabel("æŒ‡æ ‡å€¼", fontsize=12)
    plt.grid(axis='y', alpha=0.3)
    plt.tight_layout()

    # ä¿å­˜å›¾ç‰‡
    save_path = "C:/Users/LingZiheng/PycharmProjects/PythonProject/evaluation_results.png"
    plt.savefig(save_path, dpi=150, bbox_inches="tight")
    plt.show()
    print(f"ğŸ“Š è¯„ä¼°ç»“æœå›¾å·²ä¿å­˜è‡³ï¼š{save_path}")


# -------------------------- ä¸»å‡½æ•°ï¼ˆæ‰§è¡Œè¯„ä¼°ï¼‰ --------------------------
if __name__ == "__main__":
    print("=" * 60)
    print("ğŸ”¥ å¼€å§‹æ¨¡å‹é‡åŒ–è¯„ä¼°...")
    print("=" * 60)

    # 1. åŠ è½½æ¨¡å‹å’Œæ•°æ®é›†
    model = load_model(model_path, device)
    val_loader = load_val_dataset(val_img_dir, val_mask_dir)

    # 2. è®¡ç®—è¯„ä¼°æŒ‡æ ‡
    metrics = evaluate_model(model, val_loader, device)

    # 3. æ‰“å°ç»“æœ
    print("\n" + "=" * 60)
    print("ğŸ“‹ æœ€ç»ˆé‡åŒ–è¯„ä¼°ç»“æœ")
    print("=" * 60)
    for name, value in metrics.items():
        print(f"{name}: {value}")
    print("=" * 60)

    # 4. å¯è§†åŒ–ç»“æœ
    plot_metrics(metrics)