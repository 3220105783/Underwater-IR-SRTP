# -*- coding: utf-8 -*-
import os
import numpy as np
import torch
from PIL import Image
from torch.utils.data import Dataset
import torchvision.transforms as transforms

# -------------------------- æ ¸å¿ƒï¼šç»Ÿä¸€å°ºå¯¸ä¸º 512x512ï¼Œé€‚é…æ‰€æœ‰è¾“å…¥å›¾ç‰‡ --------------------------
TARGET_SIZE = (512, 512)  # ç»Ÿä¸€ç›®æ ‡å°ºå¯¸

# -------------------------- è®­ç»ƒé›† transformsï¼ˆå«æ•°æ®å¢å¼ºï¼Œå°ºå¯¸ç»Ÿä¸€ä¸º512x512ï¼‰--------------------------
train_transform_img = transforms.Compose([
    transforms.Resize(TARGET_SIZE),  # å¼ºåˆ¶ resize ä¸º 512x512ï¼ˆæ— è®ºåŸå›¾å°ºå¯¸ï¼‰
    #transforms.RandomHorizontalFlip(p=0.5),  # æ°´å¹³ç¿»è½¬ï¼ˆæ•°æ®å¢å¼ºï¼‰
    #transforms.RandomRotation(degrees=15),  # éšæœºæ—‹è½¬Â±15åº¦ï¼ˆé€‚åº”ä¸åŒè§’åº¦è£‚ç¼ï¼‰
    #transforms.RandomResizedCrop(TARGET_SIZE, scale=(0.9, 1.1)),  # è½»å¾®ç¼©æ”¾è£å‰ªï¼ˆå¢å¼ºé²æ£’æ€§ï¼‰
    #transforms.GaussianBlur(kernel_size=3, sigma=(0.1, 1.0)),  # é«˜æ–¯æ¨¡ç³Šï¼ˆé™ä½å…‰ç…§å·®å¼‚å½±å“ï¼‰
    #transforms.ColorJitter(brightness=0.3, contrast=0.3, saturation=0.2),  # é¢œè‰²æŠ–åŠ¨ï¼ˆé€‚é…é£æ ¼å·®å¼‚ï¼‰
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406],  # ImageNet æ ‡å‡†åŒ–ï¼ˆæå‡è®­ç»ƒç¨³å®šæ€§ï¼‰
                         std=[0.229, 0.224, 0.225])
])

train_transform_mask = transforms.Compose([
    transforms.Resize(TARGET_SIZE, interpolation=Image.NEAREST),  # mask ç”¨æœ€è¿‘é‚»æ’å€¼ï¼ˆä¿æŒåƒç´ çº¯å‡€ï¼‰
    #transforms.RandomHorizontalFlip(p=0.5),  # ä¸åŸå›¾åŒæ­¥ç¿»è½¬
    #transforms.RandomRotation(degrees=15),  # ä¸åŸå›¾åŒæ­¥æ—‹è½¬
    #transforms.RandomResizedCrop(TARGET_SIZE, scale=(0.9, 1.1), interpolation=Image.NEAREST),  # ä¸åŸå›¾åŒæ­¥è£å‰ª
    transforms.Lambda(lambda x: torch.from_numpy(np.array(x, dtype=np.float32)))
])

# -------------------------- éªŒè¯é›† transformsï¼ˆä»…ç»Ÿä¸€å°ºå¯¸ï¼Œæ— æ•°æ®å¢å¼ºï¼‰--------------------------
val_transform_img = transforms.Compose([
    transforms.Resize(TARGET_SIZE),  # éªŒè¯é›†ç»Ÿä¸€ä¸º 512x512
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406],
                         std=[0.229, 0.224, 0.225])
])

val_transform_mask = transforms.Compose([
    transforms.Resize(TARGET_SIZE, interpolation=Image.NEAREST),
    transforms.Lambda(lambda x: torch.from_numpy(np.array(x, dtype=np.float32)))
])

# ç»™ predict.py é¢„ç•™åˆ«å
val_transform = val_transform_img


# -------------------------- æ•°æ®é›†ç±»ï¼ˆç»Ÿä¸€å°ºå¯¸+é€‚é…å‘½åè§„åˆ™+æ— maskç­›é€‰ï¼‰--------------------------
class CrackDataset(Dataset):
    def __init__(self, img_dir, mask_dir, is_train=True, oversample=False):
        self.img_dir = img_dir
        self.mask_dir = mask_dir
        self.is_train = is_train
        self.oversample = oversample

        # 1. åŠ è½½æ‰€æœ‰æ–‡ä»¶ï¼ˆæ”¯æŒ jpg/jpeg/png/bmp æ ¼å¼ï¼‰
        img_suffixes = ('.jpg', '.jpeg', '.png', '.bmp')
        mask_suffixes = ('.jpg', '.jpeg', '.png', '.bmp')
        self.img_filenames = [f for f in os.listdir(img_dir) if f.lower().endswith(img_suffixes)]
        self.mask_filenames = [f for f in os.listdir(mask_dir) if f.lower().endswith(mask_suffixes)]

        # 2. æ–‡ä»¶ååŒ¹é…ï¼ˆæ ¸å¿ƒï¼šé€‚é… xxx.jpg â†” xxx_mask.jpgï¼‰
        self.common_filenames = []
        # å»ºç«‹ mask æ˜ å°„ï¼škey=xxxï¼ˆå‰ç¼€ï¼‰ï¼Œvalue=maskåŸå§‹æ–‡ä»¶å
        mask_name_map = {}
        for mask_name in self.mask_filenames:
            if "_mask" in mask_name.lower():  # ä»…åŒ¹é…å« "_mask" çš„ mask æ–‡ä»¶
                mask_prefix = mask_name.lower().split("_mask")[0]  # æå–å‰ç¼€ï¼ˆå¦‚ "001_mask.jpg" â†’ "001"ï¼‰
                mask_name_map[mask_prefix] = mask_name

        # åŒ¹é…åŸå›¾å’Œ maskï¼ˆåŸå›¾å‰ç¼€ == mask å‰ç¼€ï¼‰
        for img_name in self.img_filenames:
            img_prefix = os.path.splitext(img_name.lower())[0]  # åŸå›¾å‰ç¼€ï¼ˆå¦‚ "001.jpg" â†’ "001"ï¼‰
            if img_prefix in mask_name_map:
                # ä¿å­˜ï¼ˆåŸå›¾å‰ç¼€ï¼ŒmaskåŸå§‹æ–‡ä»¶åï¼‰ï¼Œç¡®ä¿åç»­èƒ½æ­£ç¡®åŠ è½½
                self.common_filenames.append((img_prefix, mask_name_map[img_prefix]))

        # 3. è¿‡é‡‡æ ·ï¼ˆå¯é€‰ï¼šè®­ç»ƒé›†å¼€å¯ï¼Œæå‡æ ·æœ¬é‡ï¼‰
        if self.is_train and self.oversample:
            self.common_filenames = self._oversample_crack_samples()

        # æ‰“å°åŠ è½½ä¿¡æ¯
        print(f"ğŸ” æ•°æ®é›†åŠ è½½è¯¦æƒ…ï¼š")
        print(f"   - æ–‡ä»¶å¤¹ï¼š{os.path.basename(img_dir)}")
        print(f"   - åŸå›¾æ€»æ•°ï¼š{len(self.img_filenames)}")
        print(f"   - maskæ€»æ•°ï¼š{len(self.mask_filenames)}")
        print(
            f"   - åŒ¹é…æ ·æœ¬æ•°ï¼š{len(self.common_filenames)}ï¼ˆ{'å«è¿‡é‡‡æ ·' if self.is_train and self.oversample else 'æ— è¿‡é‡‡æ ·'}ï¼‰")

        # æ— åŒ¹é…æ ·æœ¬æ—¶æŠ¥é”™ï¼ˆæç¤ºå‘½åè§„åˆ™ï¼‰
        if len(self.common_filenames) == 0:
            raise ValueError(
                "âŒ æ— ä»»ä½•åŒ¹é…çš„æ ·æœ¬ï¼è¯·æ£€æŸ¥ï¼š\n"
                "1. åŸå›¾å‘½åï¼šxxx.jpgï¼ˆæ”¯æŒ jpg/png ç­‰ï¼‰\n"
                "2. maskå‘½åï¼šxxx_mask.jpgï¼ˆéœ€ä¸åŸå›¾å‰ç¼€ä¸€è‡´ï¼‰\n"
                "3. ç¤ºä¾‹ï¼šåŸå›¾ 001.jpg â†’ mask 001_mask.jpg"
            )

    def _oversample_crack_samples(self):
        """è¿‡é‡‡æ ·ï¼šæ‰€æœ‰åŒ¹é…æ ·æœ¬é‡å¤2æ¬¡ï¼ˆé€‚é…å°æ•°æ®é›†ï¼‰"""
        oversampled = []
        for item in self.common_filenames:
            oversampled.extend([item] * 2)  # é‡å¤2æ¬¡ï¼Œå¯æ”¹ä¸º3æ¬¡ï¼ˆæ ¹æ®éœ€æ±‚è°ƒæ•´ï¼‰
        return oversampled

    def __len__(self):
        """è¿”å›æ ·æœ¬æ€»æ•°"""
        return len(self.common_filenames)

    def __getitem__(self, idx):
        """åŠ è½½å•æ ·æœ¬ï¼ˆè‡ªåŠ¨ç»Ÿä¸€ä¸º 512x512ï¼‰"""
        # è·å–å½“å‰æ ·æœ¬çš„ï¼ˆåŸå›¾å‰ç¼€ï¼ŒmaskåŸå§‹æ–‡ä»¶åï¼‰
        img_prefix, mask_name = self.common_filenames[idx]

        # 1. åŠ è½½åŸå›¾ï¼ˆè‡ªåŠ¨é€‚é…æ‰€æœ‰æ”¯æŒçš„åç¼€ï¼‰
        img_path = None
        for ext in ('.jpg', '.jpeg', '.png', '.bmp'):
            temp_path = os.path.join(self.img_dir, f"{img_prefix}{ext}")
            if os.path.exists(temp_path):
                img_path = temp_path
                break
        if not img_path:
            raise FileNotFoundError(f"âŒ æœªæ‰¾åˆ°åŸå›¾ï¼š{img_prefix}ï¼ˆæ”¯æŒåç¼€ï¼šjpg/jpeg/png/bmpï¼‰")

        # 2. åŠ è½½ maskï¼ˆç›´æ¥ç”¨åŒ¹é…åˆ°çš„åŸå§‹æ–‡ä»¶åï¼‰
        mask_path = os.path.join(self.mask_dir, mask_name)
        if not os.path.exists(mask_path):
            raise FileNotFoundError(f"âŒ æœªæ‰¾åˆ° mask æ–‡ä»¶ï¼š{mask_name}")

        # 3. è¯»å–å›¾ç‰‡
        image = Image.open(img_path).convert("RGB")  # åŸå›¾è½¬ä¸º RGB é€šé“
        mask = Image.open(mask_path).convert("L")  # mask è½¬ä¸ºå•é€šé“ç°åº¦å›¾

        # 4. åº”ç”¨ transformsï¼ˆè®­ç»ƒé›†å«å¢å¼ºï¼ŒéªŒè¯é›†ä»… resizeï¼‰
        if self.is_train:
            image = train_transform_img(image)
            mask = train_transform_mask(mask)
        else:
            image = val_transform_img(image)
            mask = val_transform_mask(mask)

        # 5. mask äºŒå€¼åŒ–ï¼ˆéé»‘åƒç´ >0 â†’ 1ï¼ŒèƒŒæ™¯â†’0ï¼Œæ·»åŠ é€šé“ç»´åº¦é€‚é…æ¨¡å‹ï¼‰
        mask = (mask > 0).float().unsqueeze(0)

        return image, mask